---
title: "MacとiPadでできる最強の理系リモート開発環境：iPadでコーディングしたい（かった）全ての人へ"
emoji: "🧑‍💻"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [iPad,codeserver,tailscale,MacBook,Windows]
published: True
---
# iPadでコーディングしたい（かった）全ての人へ

Apple Silicon搭載のMacでも（もちろんWindows PCでも）構築できる、理系学生・研究者のための最強のリモート開発環境について紹介します。「研究室のPCでコードを書いているけど、カフェや図書館でもコーディングしたい」「ノートパソコンを持ち歩かずにiPadだけで研究のコードを書きたい」といった願望を持つ方々に最適なソリューションです。

:::message alert
## 注意事項：ネットワーク構成と所属団体のポリシーについて

本記事で紹介している Tailscale などの P2P 通信ソフトは、**個人の開発環境や小規模なチームでの利用には非常に便利なツール**ですが、**大学・企業・研究機関などのネットワークポリシーによっては、使用が制限されている場合があります**。

**Tailscale を含む P2P 型 VPN サービスの利用に際しては、必ず事前に所属団体の情報セキュリティガイドラインやネットワーク管理部門の指示を確認してください。**

> **免責事項**  
> 本記事の内容を起因としたいかなる不利益・損害についても、筆者は一切の責任を負いかねます。導入・運用は各自の責任にてお願いいたします。
:::

## この記事でわかること

- Macをサーバー化し、iPadから開発する方法
- Apple Siliconでx86互換の開発環境を構築する方法
- Tailscaleを用いた安全なリモートアクセスの設定
- JupyterLabとCode-Serverの併用環境の構築方法
- 同じ環境を研究室のGPUマシンでも使う方法
- 任意のPC/サーバーでも再現可能な汎用性

## 必要な環境

- Docker環境が利用できるPC/サーバー（Mac/Windows/Linux）
- iPad+キーボード推奨
- インターネット接続

## システム構成

今回構築するシステムは以下のような構成になります。ホストマシンとクライアントは各自好きなデバイスを使うと良いでしょう：

1. **ホストマシン**(MacBook)：Docker上にx86 Ubuntuコンテナを展開
2. **コンテナ**：コンテナ内にJupyterLabとCode-Serverを構築
3. **接続**：Tailscaleによる安全なVPN接続
4. **クライアント**(iPad)：iブラウザでJupyterLabとCode-Serverにアクセス

↓システム構成図(てきとー)
![system.jpeg](/images/system.png)

## この構成のいい感じなところ（[読み飛ばしてOK](#セットアップ手順)）

- **マルチプラットフォーム対応**: Mac/Windows/Linuxなど、任意のホストマシンで利用可能
- **自動起動設定可能**: システム起動時に自動的にコンテナが立ち上がるよう設定可能
- **iPadだけで本格的なコーディング**: 重いノートPCを持ち歩く必要なし
- **開発環境の選択肢**: Python開発ならJupyterLabだけでも十分に実用的
- **外出先からも安全に接続**: Tailscaleによる暗号化通信
- **常に同期された環境**: どこからアクセスしても同じ状態を維持
- **永続性**: コンテナを再起動してもインストールした拡張機能やライブラリが保持される
- **自動バックアップ**: 予期せぬシャットダウンからデータを保護
- **GPU環境との互換性**: 同じ環境をGPUマシンでもシームレスに使える

これにより、研究室・自宅・カフェなど場所を選ばず、いつでも同じ環境で開発作業ができるようになります。特に、Apple SiliconのMacユーザーが直面する「x86環境との互換性問題」も解決できます。

### MacBookに限定されない汎用性

この環境構成の大きな特徴は、**MacBookに限らず任意のコンピュータで利用できる**点です。以下のような様々なシナリオで活用できます：

- 研究室に置きっぱなしのWindows PC
- 学科のLinuxサーバー
- クラウド上のVMインスタンス
- 自宅のデスクトップPC

Dockerが動く環境であれば、どこでもほぼ同じ設定でホスト可能です。これにより、常に電源を入れっぱなしにできない MacBook の制約を超えて、常時アクセス可能な環境を構築できます。

### 自動起動と手動操作不要の環境

システム設定を調整することで、ホストマシンの起動時に自動的にコンテナを立ち上げられます：

- **Linux**: systemdサービスとして登録
- **Windows**: タスクスケジューラに登録
- **Mac**: Launch Agentとして登録

これにより、「コンテナ起動のコマンドを叩く」といった手動操作が不要になります。一度設定すれば、ホストマシンが起動していれば常にアクセス可能な状態が維持されます。

### Python開発ならJupyterLabだけでも十分！

Code-Serverは多言語対応の強力なエディタですが、Python開発だけなら**JupyterLabだけでも十分に実用的**です：

- **コードの編集**: JupyterLab内蔵のテキストエディタで複数ファイルの編集が可能
- **対話的開発**: セルごとの実行による迅速な試行錯誤
- **可視化**: グラフやデータテーブルのインタラクティブな表示
- **ドキュメント化**: Markdownとコードを組み合わせたレポート作成
- **ターミナル統合**: JupyterLab内でターミナルが使用可能

特に機械学習や科学計算の分野では、JupyterLabだけで研究の大部分をカバーできます。

### GPUマシンとの互換性：どこでも同じ環境を

この環境構成の特筆すべき点は、**わずかな修正だけで研究室のGPUマシンでも利用できる**ことです。

#### GPUマシンへの拡張方法

リポジトリのDockerfileとdocker-compose.ymlを少し修正するだけで、NVIDIAのGPUを搭載した研究室のマシンでも全く同じ環境を構築できます：

1. **ベースイメージの変更**:
   - Dockerfileの最初の行を `FROM --platform=linux/amd64 ubuntu:22.04` から 
   - `FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04` のようにGPU対応イメージに変更

2. **docker-composeの修正**:
   - docker-compose.ymlにGPUサポートを追加
   ```yaml
   services:
     ml_env:
       # 他の設定はそのまま
       deploy:
         resources:
           reservations:
             devices:
               - driver: nvidia
                 capabilities: [gpu]
   ```

3. **ライブラリの追加**:
   - GPUに対応したTensorFlowやPyTorchのバージョンを指定

この修正により、以下のようなワークフローが実現します：

1. 自宅のMacで軽量なモデル開発やデバッグを行う
2. 開発した環境を研究室のGPUマシンに移行
3. 重い計算やトレーニングを実行
4. 結果を確認するためにiPadからアクセス

これにより、「開発はMacで、トレーニングはGPUマシンで」という理想的な研究環境が構築できます。

## セットアップ手順

実際のセットアップは以下のGitHubリポジトリを参照してください：
[https://github.com/k1nsenka/ubuntu-code-server-container](https://github.com/k1nsenka/ubuntu-code-server-container)

このリポジトリには、環境構築に必要なDockerfile、docker-compose.yml、各種スクリプトが含まれています。詳細な手順はREADMEに記載されていますが、基本的な流れは以下の通りです：

1. リポジトリをクローン
2. 環境を起動（実行権限を付与してから `./start-container.sh` を実行）
3. JupyterLabとCode-Serverの起動
4. TailscaleでホストマシンとiPadを接続

## Tailscaleによるセキュアなアクセス設定

安全なリモートアクセスのためには、Tailscaleの使用をお勧めします。Tailscaleはデバイス間を簡単かつ安全に接続できるVPNサービスです。

**詳細なセットアップ手順については、[Tailscale公式サイト](https://tailscale.com/kb/installation)を参照してください。** 公式ドキュメントには各プラットフォーム向けの詳しいガイドが掲載されています。

基本的には以下の流れでセットアップできます：
1. 各デバイスにTailscaleをインストール（ホストマシンとiPad）
2. 同じアカウントにログイン
3. 自動的にセキュアなネットワークが構築される

Tailscaleを使用すると、IPアドレスを気にせず、デバイス名でアクセスできるようになります。ここでのホスト名はMagicDNSと呼ばれるものです：
- `http://[ホスト名]:8080` → Code-Server
- `http://[ホスト名]:8888` → JupyterLab

## 実際の使用例[読み飛ばしてOK](#おわりに)

これまで研究室のデスクトップで行っていた作業が、以下のようにいつでもどこでも可能になります：

- 通学中の電車内でiPadからコードを書く
- 図書館で論文を読みながらコードを修正する
- カフェでデータ分析結果を確認する
- 学会発表前の最終調整を外出先で行う
- **Macでプロトタイプ開発後、研究室のGPUマシンで大規模モデルのトレーニングを実行**
- **トレーニング終了後、iPadから結果をチェックして次の実験を計画**
- **サーバーで24時間常時稼働させて長時間の計算を実行しながら外出**

iPadとキーボードだけという軽装備で、フル機能の開発環境にアクセスできるのは革命的です。特にGPUマシンで実行中の長時間の実験結果を、帰宅途中の電車の中でチェックできるのは研究効率を大幅に向上させます。

### 研究スタイルの革新：場所を選ばない開発環境

この環境の最大の魅力は、開発環境と計算環境の分離を実現しながらも、ユーザー体験としては一貫性を保てることです。

例えば、次のようなワークフローが可能になります：

1. **プロトタイピング** (任意のPC):
   - 自宅のPCでアルゴリズムやモデルの小規模版を開発
   - Python開発であればJupyterLabだけでも快適に作業可能

2. **大規模計算** (研究室GPU):
   - 同じDockerfile（GPU版）で研究室マシンに環境をデプロイ
   - 大規模データセットでの学習を実行

3. **モニタリング** (iPad):
   - カフェや図書館からiPadでトレーニング進捗をチェック
   - 必要に応じてハイパーパラメータを調整

4. **結果分析** (どこからでも):
   - トレーニング完了後の結果をJupyterLabで分析
   - 新たな実験のアイデアをその場でコーディング

このように、「どこで開発するか」「どこで計算するか」「どこでチェックするか」の制約から解放され、最適な場所で最適な作業ができるようになります。

## おわりに

私はiPad Proで何度も何度も何度も開発環境構築を試みました。理想的なのはやはりiPad自身でvmをエミュレートしてアクセスし、コーディングを行うことですよね。無理なんです。100000年間試してきました。いいエディタもないですし。

とはいえ今回紹介した方法で、任意のホストマシンで環境を構築し、iPadからシームレスにアクセスできるようになります。MacBook特有の制約（バッテリー駆動など）にも縛られず、常時アクセス可能な環境を実現できます。

特にPython開発に焦点を当てている場合は、JupyterLabだけでも十分な機能性を発揮できます。さらに、同じ環境をGPUマシンにも展開できるため、研究のフローを大幅に効率化できます。

研究効率の向上、場所の制約からの解放、そして何より「iPadだけ（？本当にだけか...？）で本格的な開発ができる」という喜びをぜひ体験してみてください。

質問やフィードバックがあれば、GitHubリポジトリのIssueでお待ちしています。皆さんの研究生活がより快適なものになることを願っています！


### 参考リンク

- [ubuntu-code-server-container リポジトリ](https://github.com/k1nsenka/ubuntu-code-server-container)
- [Tailscale公式サイト](https://tailscale.com/)
- [Tailscaleインストールガイド](https://tailscale.com/kb/installation)
- [code-server 公式ドキュメント](https://coder.com/docs/code-server)
- [JupyterLab 公式ドキュメント](https://jupyterlab.readthedocs.io/)
- [NVIDIA Docker GitHub](https://github.com/NVIDIA/nvidia-docker)
